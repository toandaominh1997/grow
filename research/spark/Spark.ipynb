{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ae701f6-0893-4803-a2a5-78e4787e8c50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.3.0'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pyspark.pandas as ps\n",
    "import pandas as pd\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# spark = SparkSession.builder.getOrCreate()\n",
    "# sc = pyspark.SparkContext.builder.(master=\"spark://127.0.0.1:7077\", appName=\"maps_and_lazy_evaluation_example\")\n",
    "spark = SparkSession.builder.appName(\"Iris\").getOrCreate()\n",
    "sc = pyspark.SparkConf()\n",
    "spark.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e51e84d-bc42-4fd5-b9ae-a7a0998db1ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------------+-----------------+----------------+------+\n",
      "|sepal length (cm)|sepal width (cm)|petal length (cm)|petal width (cm)|target|\n",
      "+-----------------+----------------+-----------------+----------------+------+\n",
      "|              5.1|             3.5|              1.4|             0.2|     0|\n",
      "|              4.9|             3.0|              1.4|             0.2|     0|\n",
      "|              4.7|             3.2|              1.3|             0.2|     0|\n",
      "|              4.6|             3.1|              1.5|             0.2|     0|\n",
      "|              5.0|             3.6|              1.4|             0.2|     0|\n",
      "|              5.4|             3.9|              1.7|             0.4|     0|\n",
      "|              4.6|             3.4|              1.4|             0.3|     0|\n",
      "|              5.0|             3.4|              1.5|             0.2|     0|\n",
      "|              4.4|             2.9|              1.4|             0.2|     0|\n",
      "|              4.9|             3.1|              1.5|             0.1|     0|\n",
      "+-----------------+----------------+-----------------+----------------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X, y = load_iris(return_X_y=True, as_frame= True)\n",
    "df = X\n",
    "df['target'] = y\n",
    "df = spark.createDataFrame(df)\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a7f1adda-9495-499f-b304-161cf34bf63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------------+-----------------+----------------+------+-----------------+\n",
      "|sepal length (cm)|sepal width (cm)|petal length (cm)|petal width (cm)|target|         features|\n",
      "+-----------------+----------------+-----------------+----------------+------+-----------------+\n",
      "|              5.1|             3.5|              1.4|             0.2|     0|[5.1,3.5,1.4,0.2]|\n",
      "|              4.9|             3.0|              1.4|             0.2|     0|[4.9,3.0,1.4,0.2]|\n",
      "|              4.7|             3.2|              1.3|             0.2|     0|[4.7,3.2,1.3,0.2]|\n",
      "|              4.6|             3.1|              1.5|             0.2|     0|[4.6,3.1,1.5,0.2]|\n",
      "|              5.0|             3.6|              1.4|             0.2|     0|[5.0,3.6,1.4,0.2]|\n",
      "+-----------------+----------------+-----------------+----------------+------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# vectorize all numerical columns into a single feature column\n",
    "feature_cols = df.columns[:-1]\n",
    "assembler = pyspark.ml.feature.VectorAssembler(inputCols=feature_cols, outputCol='features')\n",
    "data = assembler.transform(df)\n",
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c41dfa73-7488-4134-b5d8-c136cfd2cf93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------+-----+\n",
      "|         features|target|label|\n",
      "+-----------------+------+-----+\n",
      "|[5.1,3.5,1.4,0.2]|     0|  0.0|\n",
      "|[4.9,3.0,1.4,0.2]|     0|  0.0|\n",
      "|[4.7,3.2,1.3,0.2]|     0|  0.0|\n",
      "|[4.6,3.1,1.5,0.2]|     0|  0.0|\n",
      "|[5.0,3.6,1.4,0.2]|     0|  0.0|\n",
      "+-----------------+------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# convert text labels into indices\n",
    "data = data.select(['features', 'target'])\n",
    "label_indexer = pyspark.ml.feature.StringIndexer(inputCol='target', outputCol='label').fit(data)\n",
    "data = label_indexer.transform(data)\n",
    "data.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f0236302-1bd0-4633-869f-d2f3347e4584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading for machine learning\n",
      "+-----------------+-----+\n",
      "|         features|label|\n",
      "+-----------------+-----+\n",
      "|[5.1,3.5,1.4,0.2]|  0.0|\n",
      "|[4.9,3.0,1.4,0.2]|  0.0|\n",
      "|[4.7,3.2,1.3,0.2]|  0.0|\n",
      "|[4.6,3.1,1.5,0.2]|  0.0|\n",
      "|[5.0,3.6,1.4,0.2]|  0.0|\n",
      "+-----------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# only select the features and label column\n",
    "data = data.select(['features', 'label'])\n",
    "print(\"Reading for machine learning\")\n",
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d162df78-415a-4707-ae9e-4536e1a87e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = data.randomSplit([0.70, 0.30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "acfe0fda-45dc-4a62-93e6-68817ed4358d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "pipe = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8, family=\"multinomial\")\n",
    "\n",
    "pipe = pipe.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b1a40c4a-c58b-448e-bef8-ece2be5eedb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[features: vector, label: double, rawPrediction: vector, probability: vector, prediction: double]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = pipe.transform(test)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e9109c08-eee3-400b-b4b2-d3f9e0eb185b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5813953488372093"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = pyspark.ml.evaluation.MulticlassClassificationEvaluator(metricName='accuracy')\n",
    "accuracy = evaluator.evaluate(prediction)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4afc62-7eef-4cf7-971e-90fcb5f57224",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539955c4-3ac6-4a35-a23e-afa7be3e72b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
